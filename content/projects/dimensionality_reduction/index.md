---
title: 'Beyond classical dimensionality reduction techniques'
# subtitle: 'Matematyczne aspekty koncepcji dryftu danych w kontekście współczesnych metod uczenia maszynowego'

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
  - admin

# Author notes (optional)
date: '2023-03-21T00:00:00Z'
doi: ''

# Schedule page publish date (NOT publication's date).
publishDate: '2017-01-01T00:00:00Z'

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ['7']

# Publication name and optional abbreviated publication name.
# publication: In *Wowchemy Conference*
# publication_short: In *ICW*

# (abstract: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.)

# Summary. An optional shortened abstract.
# summary: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.)

tags: ["Bachelor", "Free", "ML", "Remote Sensing"]

# Display this page in the Featured widget?
featured: false

# Custom links (uncomment lines below)
# links:
#  - name: Custom Link
#    url: http://example.org

url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: 'https://towardsdatascience.com/11-dimensionality-reduction-techniques-you-should-know-in-2021-dcb9500d388b'
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
  - []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---

Dimensionality reduction is a technique used in machine learning to reduce the number of features in a dataset. This can help to improve the performance of machine learning models by reducing the amount of noise and redundancy in the data, as well as making the data more computationally efficient to process. Some of the modern methods of dimensionality reduction include:

Principal Component Analysis (PCA): PCA is a popular technique used to reduce the dimensionality of a dataset by identifying the principal components that explain the most variance in the data. It works by projecting the data onto a new set of orthogonal axes, with each axis representing a principal component.

t-Distributed Stochastic Neighbor Embedding (t-SNE): t-SNE is a nonlinear dimensionality reduction technique that is particularly effective for visualizing high-dimensional data. It works by mapping the high-dimensional data points to a low-dimensional space, while preserving the pairwise distances between the data points.

Autoencoders: Autoencoders are neural networks that can be used for unsupervised learning and dimensionality reduction. They work by compressing the input data into a lower-dimensional representation, and then reconstructing the original input from this compressed representation.

Non-negative Matrix Factorization (NMF): NMF is a matrix factorization technique that can be used for dimensionality reduction and feature extraction. It works by factorizing a non-negative matrix into two non-negative matrices, where the resulting factors can be interpreted as a lower-dimensional representation of the original data.

UMAP (Uniform Manifold Approximation and Projection): UMAP is a newer technique for dimensionality reduction that is gaining popularity. It works by constructing a low-dimensional representation of the data that preserves both local and global structure, making it particularly useful for clustering and visualization tasks.

These modern methods of dimensionality reduction offer a range of options to choose from, and selecting the most appropriate technique for a particular dataset depends on the nature of the data and the specific goals of the analysis.
