{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Daniel Kucharczyk is an Assistant Professor with the Faculty od Pure and Applied Mathematics at Wroclaw University of Technology.  His research interests include the application of mathematics and AI/ML methods in:</p> <ul> <li>finance,</li> <li>remote sensing.</li> </ul> <p>In addition, he has been actively working in the following fields:</p> <ul> <li>reproducible research,</li> <li>scientific computing,</li> <li>cloud software architecture.</li> </ul>"},{"location":"#contact-information","title":"Contact Information","text":"<ul> <li>Lecturer: dr in\u017c. Daniel Kucharczyk</li> <li>Email: daniel.kucharczyk[at]pwr.edu.pl</li> <li>Office Hours: </li> <li>Schedule Meeting</li> <li>Location: Hoene-Wro\u0144skiego Street 13c, 50-376 Wroc\u0142aw</li> <li>Room: Building C-19, room A.4.18</li> <li></li> </ul>"},{"location":"blog/","title":"Machine Learning WUST 2024/2025","text":"<p>Welcome to the official blog for the Machine Learning course at Wroclaw University of Technology. This site documents the teaching activities for graduate students in Applied Mathematics during the Winter Semester of 2024/2025.</p>"},{"location":"blog/2024/10/03/course-administrative-guide/","title":"Course Administrative Guide","text":"<p>The review of the course syllabus, grading policy, assignment schedule, and available resources to ensure everyone understands the expectations and logistics for our journey into machine learning and reproducible research.</p>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#course-overview","title":"Course Overview","text":"<ul> <li>Name: Machine Learning</li> <li>Course Code: W13AMA-SM2338G</li> <li>Prerequisites:<ul> <li>Fundamental understanding of linear algebra</li> <li>Basic understanding of multivariable calculus concepts and optimization algorithm</li> <li>Ability to write a non-trivial computer program in Python or equivalent</li> <li>Working knowledge of GitHub.</li> </ul> </li> </ul>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#learning-objectives","title":"Learning Objectives","text":"","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#foundational-concepts","title":"Foundational Concepts","text":"<ul> <li>Explain the fundamental principles of machine learning and deep learning</li> <li>Describe the historical development of neural networks and deep learning</li> <li>Define and explain the function of a perceptron</li> <li>Illustrate the structure and operation of artificial neurons</li> <li>Differentiate between various activation functions and their use cases</li> </ul>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#neural-network-architectures","title":"Neural Network Architectures","text":"<ul> <li>Design and implement basic feedforward neural networks</li> <li>Analyze the architecture of Convolutional Neural Networks (CNNs) and their applications in image processing</li> <li>Examine the structure of Recurrent Neural Networks (RNNs) and their use in sequential data processing</li> <li>Evaluate the improvements offered by Long Short-Term Memory (LSTM) networks over traditional RNNs</li> </ul>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#training-and-optimization","title":"Training and Optimization","text":"<ul> <li>Explain the concept of backpropagation and its role in neural network training</li> <li>Compare and contrast different gradient descent methods (e.g., stochastic, mini-batch, batch)</li> <li>Implement various optimization algorithms to improve model performance</li> </ul>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#practical-implementation","title":"Practical Implementation","text":"<ul> <li>Utilize NumPy to build neural networks from scratch</li> <li>Develop deep learning models using high-level frameworks such as Keras and PyTorch</li> <li>Apply CNN architectures to solve image classification problems</li> <li>Implement RNN and LSTM models for natural language processing tasks</li> </ul>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Discuss regularization techniques to prevent overfitting in deep learning models</li> <li>Explore transfer learning and its applications in various domains</li> <li>Evaluate the ethical implications and potential biases in deep learning systems</li> </ul>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#project-work","title":"Project Work","text":"<ul> <li>Design, implement, and evaluate a deep learning solution for a real-world problem</li> <li>Present and defend the choices made in model architecture and training process</li> </ul>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#critical-analysis","title":"Critical Analysis","text":"<ul> <li>Compare the performance of different deep learning architectures on various tasks</li> <li>Critically analyze current research papers in the field of deep learning</li> <li>Identify limitations and potential future directions in deep learning research</li> </ul>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#grading-policy","title":"Grading Policy","text":"<ul> <li>Assignments: 70%</li> <li>Project: 30%</li> </ul> <p>Grading Scale:</p> Percents Grade &gt;90% 5 [80%, 90%) 4.5 [70%, 80%) 4 [60%, 70%) 3.5 [50%, 60%) 3","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#assignments-and-projects","title":"Assignments and Projects","text":"<ul> <li>Weekly programming assignments due every Wednesday by 11:59 PM.</li> <li>Late submissions: 10% penalty per day, up to 3 days</li> <li>Final project proposal and team formation (max. 3 persons) due Week 8 (21st of November, 2024),</li> <li>Final project presentation during the last week of classes (30rd of January, 2025),</li> </ul>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#academic-integrity","title":"Academic Integrity","text":"<ul> <li>All submitted work must be original</li> <li>Collaboration on assignments is encouraged, but submitted code must be individual work</li> <li>Plagiarism or cheating will result in a failing grade for the assignment and possible disciplinary action</li> </ul>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#attendance-policy","title":"Attendance Policy","text":"<ul> <li>Attendance is not mandatory for all lectures and lab sessions</li> </ul>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#projects","title":"Projects","text":"<ul> <li>Examples</li> <li>Project template:  https://github.com/opencompl/paper-template?tab=readme-ov-file</li> </ul>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#references","title":"References","text":"","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#machine-learning","title":"Machine Learning","text":"<ol> <li> <p>The Elements of Statistical Learning by Trevor Hastie, Robert Tibshirani, and Jerome Friedman.</p> </li> <li> <p>Pattern Recognition and Machine Learning by Christopher Bishop.</p> </li> <li> <p>Introduction to Machine Learning with Python by Andreas C. M\u00fcller &amp; Sarah Guido.</p> </li> <li> <p>Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow by Aur\u00e9lien G\u00e9ron.</p> </li> </ol>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#deep-learning","title":"Deep Learning","text":"<ol> <li> <p>Deep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville</p> </li> <li> <p>Neural Networks and Deep Learning by Michael Nielsen.</p> </li> <li> <p>Deep Learning with Python by Fran\u00e7ois Chollet.</p> </li> <li> <p>Grokking Deep Learning by Andrew W. Trask.</p> </li> </ol>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/course-administrative-guide/#specialized-topics","title":"Specialized Topics","text":"<ol> <li> <p>Natural Language Processing with Transformers by Lewis Tunstall, Leandro von Werra, and Thomas Wolf.</p> </li> <li> <p>Reinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto.</p> </li> <li> <p>Computer Vision: Algorithms and Applications by Richard Szeliski.</p> </li> <li> <p>Probabilistic Graphical Models: Principles and Techniques by Daphne Koller and Nir Friedman.</p> </li> </ol>","tags":["Machine Learning","Winter 2024/2025"]},{"location":"blog/2024/10/03/week-1---introduction-to-machine-learning-and-reproducible-research/","title":"Week #1 - Introduction to Machine Learning and Reproducible Research","text":"<p>In the second part of our first lecture, we will embark on an exciting journey into the world of machine learning (ML) and the critical importance of reproducible research.</p> <p>Learning objectives:</p> <ul> <li>Define and differentiate between Artificial Intelligence, Machine Learning, and Deep Learning.</li> <li>Identify and explain the main types of machine learning.</li> <li>Recognize common real-world applications of machine learning across various industries.</li> <li>Understand the basic workflow of a machine learning project, from data collection to model deployment using reproducible research principles.</li> </ul> <p>Laboratory https://classroom.github.com/a/3KtoTnWw</p>"},{"location":"blog/2024/10/10/week-2---linear-regression-model/","title":"Week #2 - Linear Regression model","text":"<p>The review of the liner regression models in the context of machine learning and the usage of gradient descent method.</p> <p>Learning objectives:</p> <ul> <li>Understand and explain the objective function in linear regression, including its mathematical formulation and underlying rationale.</li> <li>Master both the closed-form solution and gradient descent approach for linear regression, including their mathematical derivations.</li> <li>Demonstrate proficiency in expressing linear regression solutions using matrix and vector operations.</li> <li>Explore how linear regression can model nonlinear relationships through the application of feature maps.</li> <li>Implement and compare closed-form and gradient descent solutions for linear regression using Python, emphasizing practical coding skills and algorithmic understanding.</li> </ul> <p>Laboratory</p> <p>https://classroom.github.com/a/5B0qAInA</p>"},{"location":"blog/2024/10/17/week-3---supervised-machine-learning/","title":"Week #3 - Supervised Machine Learning","text":"<p>Learning objectives:</p> <ul> <li>Formalize the supervised machine learning setup, including understanding the concepts of training data, feature spaces, label spaces, and hypothesis functions.</li> <li>Comprehend different types of classification problems (binary, multi-class) and regression, along with their corresponding label spaces and feature vector characteristics.</li> <li>Understand the process of learning a hypothesis function, including selecting an appropriate algorithm and finding the best function within the hypothesis class using loss functions.</li> <li>Grasp the concept of generalization and the importance of train/test splits to address overfitting concerns, including the role of validation data in model development.</li> <li>Learn how to properly train and evaluate a classifier, including the formulas for minimizing training loss and calculating testing loss, as well as understanding how these relate to the true generalization loss.</li> </ul> <p>Laboratory</p> <p>https://classroom.github.com/a/AUoF7uBb</p>"},{"location":"blog/2024/10/24/week-4---model-selection-and-hyperparameter-tuning/","title":"Week #4 - Model Selection and Hyperparameter Tuning","text":"<p>Learning objectives:</p> <ul> <li>Explain the importance of model selection and hyperparameter tuning in improving machine learning model performance, including the relationship between model complexity, bias, and variance</li> <li>Apply cross-validation techniques (k-fold, stratified, time-series) to evaluate model performance and select optimal models while avoiding overfitting</li> <li>Implement automated hyperparameter tuning methods such as Grid Search, Random Search, and Bayesian Optimization to efficiently find optimal model configurations</li> <li>Compare and evaluate different models using appropriate metrics (accuracy, precision, recall, F1-score, ROC-AUC) to make informed decisions about model selection based on the specific problem requirements and constraints</li> <li>Understand and apply regularization techniques (L1, L2, Elastic Net) to control model complexity and prevent overfitting during the model selection process</li> </ul> <p>Laboratory</p> <p>https://classroom.github.com/a/NhRt73hM</p>"},{"location":"blog/2024/11/14/week-5---introduction-to-neural-networks/","title":"Week #5 - Introduction to Neural Networks","text":"<p>In today's lecture, we'll explore the foundational journey of neural networks, starting with the McCulloch-Pitts neuron model and progressing through Rosenblatt's perceptron, examining their capabilities with logic gates, understanding the XOR problem limitation, and discovering how these early challenges shaped the development of more advanced network architectures.</p> <p>Learning objectives: - Explain the historical significance of the McCulloch-Pitts neuron model (1943) and describe its basic components, including binary inputs, threshold activation, and binary output. - Compare and contrast the McCulloch-Pitts neuron with Rosenblatt's perceptron model, highlighting key advancements such as weighted connections and the learning algorithm. - Demonstrate how to solve linearly separable problems using the perceptron model through simple examples like AND and OR gates. - Analyze why the XOR problem cannot be solved by a single perceptron, using geometric visualization to explain the concept of linear separability. - Evaluate the limitations of early neural network models and explain how these limitations influenced the development of multilayer networks.</p> <p>Laboratory</p> <p>https://classroom.github.com/a/2BzNhU74</p>"},{"location":"blog/2024/11/21/week-6---multilayer-perceptrons/","title":"Week #6 - Multilayer Perceptrons","text":"<p>In today's lecture, we'll dive into multilayer perceptrons (MLPs), understanding how these more sophisticated neural networks overcome the limitations of single-layer models by utilizing hidden layers, backpropagation for learning, and their ability to solve complex non-linear problems that form the foundation of modern deep learning architectures.</p> <p>Learning objectives: - Explain the architecture of multilayer perceptrons and how hidden layers enable non-linear function approximation - Understand the mathematics behind the backpropagation algorithm and its role in training MLPs - Explore the Universal Approximation Theorem and its implications for MLP capabilities and limitations - Implement and train an MLP to solve the XOR problem, demonstrating the advantage over single-layer perceptrons - Explore activation functions (sigmoid, tanh, ReLU) and their impact on network performance and training dynamics - Apply MLPs to real-world classification and regression problems, including techniques for avoiding overfitting</p> <p>Laboratory TBA</p> <p>Resources - https://brilliant.org/wiki/artificial-neural-network/ - https://brilliant.org/wiki/feedforward-neural-networks/ - https://brilliant.org/wiki/backpropagation/</p>"},{"location":"user-guide/clean_code/","title":"Clean Code","text":"<p>Writing clean, readable, and maintainable code is crucial for reproducible research. This section covers Python coding standards, linting, and formatting tools to help you write high-quality, consistent code.</p>"},{"location":"user-guide/clean_code/#pep-8-style-guide-for-python-code","title":"PEP 8: Style Guide for Python Code","text":"<p>PEP 8 is the official style guide for Python code. Following PEP 8 ensures consistency across Python projects. Key points include:</p> <ol> <li>Indentation: Use 4 spaces per indentation level.</li> <li>Maximum Line Length: Limit lines to 79 characters for code, 72 for comments and docstrings.</li> <li>Imports: Place imports at the top of the file, grouped in the following order:<ul> <li>Standard library imports</li> <li>Related third-party imports</li> <li>Local application/library specific imports</li> </ul> </li> <li>Whitespace: Use blank lines to separate functions and classes, and larger blocks of code inside functions.</li> <li>Naming Conventions:<ul> <li>Functions, variables, and attributes: <code>lowercase_with_underscores</code></li> <li>Classes: <code>CapitalizedWords</code></li> <li>Constants: <code>ALL_CAPS</code></li> </ul> </li> <li>Comments: Use inline comments sparingly. Write docstrings for all public modules, functions, classes, and methods.</li> </ol>"},{"location":"user-guide/clean_code/#linting","title":"Linting","text":"<p>Linting helps identify programming errors, bugs, stylistic errors, and suspicious constructs. Popular Python linters include:</p> <ol> <li> <p>Pylint: A comprehensive linter that checks for errors, enforces a coding standard, and looks for code smells.       Installation:       <code>pip install pylint</code>       Usage:       <code>pylint your_script.py</code></p> </li> <li> <p>Flake8: Combines PyFlakes, pycodestyle, and McCabe complexity checker.</p> </li> </ol> <p>Installation:    <code>pip install flake8</code>    Usage:    <code>flake8 your_script.py</code></p> <ol> <li>Mypy: A static type checker for Python.</li> </ol> <p>Installation:    <code>pip install mypy</code>    Usage:    <code>mypy your_script.py</code></p>"},{"location":"user-guide/clean_code/#formatting","title":"Formatting","text":"<p>Automatic formatters help maintain consistent code style across your project:</p> <ol> <li>Black: An opinionated formatter that adheres to PEP 8 guidelines.</li> </ol> <p>Installation:    <code>pip install black</code>    Usage:    <code>black your_script.py</code></p> <ol> <li>YAPF (Yet Another Python Formatter): A formatter by Google that's highly configurable.</li> </ol> <p>Installation:    <code>pip install yapf</code>    Usage:    <code>yapf -i your_script.py</code></p> <ol> <li>isort: A utility to sort imports alphabetically and automatically separate them into sections.</li> </ol> <p>Installation:    <code>pip install isort</code>    Usage:    <code>isort your_script.py</code></p>"},{"location":"user-guide/clean_code/#additional-best-practices","title":"Additional Best Practices","text":"<ol> <li> <p>DRY (Don't Repeat Yourself): Avoid duplicating code. Extract repeated logic into functions.</p> </li> <li> <p>KISS (Keep It Simple, Stupid): Write simple, straightforward code. Avoid over-engineering.</p> </li> <li> <p>YAGNI (You Aren't Gonna Need It): Don't add functionality until it's necessary.</p> </li> <li> <p>Write Self-Documenting Code: Choose descriptive variable and function names that explain their purpose.</p> </li> <li> <p>Use Type Hints: Employ Python's type hinting system to improve code clarity and catch type-related errors early.</p> </li> </ol> <p>Example:    <code>python    def greet(name: str) -&gt; str:        return f\"Hello, {name}!\"</code></p> <ol> <li> <p>Error Handling: Use try/except blocks to handle exceptions gracefully.</p> </li> <li> <p>Testing: Write unit tests for your functions and classes using frameworks like pytest.</p> </li> </ol>"},{"location":"user-guide/clean_code/#integrating-with-your-workflow","title":"Integrating with Your Workflow","text":"<ol> <li> <p>Pre-commit Hooks: Use pre-commit to run linters and formatters automatically before each commit.</p> </li> <li> <p>CI/CD Integration: Include linting and formatting checks in your Continuous Integration pipeline.</p> </li> <li> <p>IDE Integration: Configure your IDE (like PyCharm or VS Code) to run linters and formatters on save.</p> </li> </ol> <p>By following these guidelines and using these tools, you'll produce cleaner, more maintainable, and more reproducible code. Remember, consistency is key in collaborative projects, so agree on a style guide with your team and stick to it throughout your research project.</p>"},{"location":"user-guide/getting_started/","title":"Getting Started","text":"<p>Setting up a consistent and reproducible development environment is crucial for conducting reproducible research. This section will guide you through the process of setting up Python environment, along with an Integrated Development Environment (IDE).</p>"},{"location":"user-guide/getting_started/#1-python-distribution","title":"1. Python distribution","text":"<p>Miniconda is popular distribution system for Python and R, designed for scientific computing. It simplifies package management and deployment.</p> <ol> <li>Visit the Miniconda website and download the appropriate installer.</li> <li>Run the installer and follow the prompts.</li> <li>Miniconda provides a base Python installation with conda package manager.</li> </ol>"},{"location":"user-guide/getting_started/#2-creating-a-conda-environment","title":"2. Creating a Conda Environment","text":"<p>After Miniconda, create a new environment for your research project:</p> <ol> <li>Open a terminal (or Anaconda Prompt on Windows).</li> <li>Create a new environment named <code>myresearch</code> with <code>python 3.9</code>:    <code>conda create --name myresearch python=3.9</code></li> <li>Activate the environment:    <code>conda activate myresearch</code></li> <li>Install necessary packages:    <code>conda install numpy pandas matplotlib scipy</code></li> </ol>"},{"location":"user-guide/getting_started/#3-setting-up-an-ide","title":"3. Setting Up an IDE","text":"<p>An Integrated Development Environment (IDE) can significantly enhance your productivity. Here's how to set up two popular IDEs:</p>"},{"location":"user-guide/getting_started/#pycharm","title":"PyCharm","text":"<ol> <li>Download and install PyCharm (Community Edition is free).</li> <li>Open PyCharm and create a new project.</li> <li>In the project settings, set the Python interpreter to your conda environment:</li> <li>Go to File &gt; Settings (on Windows/Linux) or PyCharm &gt; Preferences (on macOS).</li> <li>Navigate to Project &gt; Python Interpreter.</li> <li>Click the gear icon and select \"Add\".</li> <li>Choose \"Conda Environment\" and select the environment you created.</li> </ol>"},{"location":"user-guide/getting_started/#visual-studio-code","title":"Visual Studio Code","text":"<ol> <li>Download and install Visual Studio Code.</li> <li>Install the Python extension from the VS Code Marketplace.</li> <li>Open your project folder in VS Code.</li> <li>Press Ctrl+Shift+P (or Cmd+Shift+P on macOS) to open the command palette.</li> <li>Type \"Python: Select Interpreter\" and choose your conda environment.</li> </ol>"},{"location":"user-guide/getting_started/#project-jupyter","title":"Project Jupyter*","text":"<p>To provides interactive notebook environments ideal for reproducible research.    Official website: Project Jupyter,</p>"},{"location":"user-guide/getting_started/#4-version-control","title":"4. Version Control","text":"<p>To ensure reproducibility, use version control for your code:</p> <ol> <li>Install Git if not already installed.</li> <li>Initialize a Git repository in your project folder:    <code>git init</code></li> <li>Create a <code>.gitignore</code> file to exclude unnecessary files. You can use gitignore.io to generate a suitable <code>.gitignore</code> file for your project.</li> <li>Make your initial commit:    <code>git add .    git commit -m \"Initial commit\"</code></li> </ol>"},{"location":"user-guide/getting_started/#additional-resources","title":"Additional resources","text":"<p>For further reading on reproducible research practices, consider exploring resources from:</p> <ul> <li>The Turing Way</li> <li>Software Carpentry</li> </ul>"},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/category/machine-learning/","title":"Machine Learning","text":""},{"location":"blog/category/winter-20242025/","title":"Winter 2024/2025","text":""}]}