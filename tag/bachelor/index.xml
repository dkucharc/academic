<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bachelor | DK's page</title><link>https://dkucharc.github.io/academic/tag/bachelor/</link><atom:link href="https://dkucharc.github.io/academic/tag/bachelor/index.xml" rel="self" type="application/rss+xml"/><description>Bachelor</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 21 Mar 2023 00:00:00 +0000</lastBuildDate><image><url>https://dkucharc.github.io/academic/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url><title>Bachelor</title><link>https://dkucharc.github.io/academic/tag/bachelor/</link></image><item><title>Beyond classical dimensionality reduction techniques</title><link>https://dkucharc.github.io/academic/projects/dimensionality_reduction/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://dkucharc.github.io/academic/projects/dimensionality_reduction/</guid><description>&lt;p>Dimensionality reduction is a technique used in machine learning to reduce the number of features in a dataset. This can help to improve the performance of machine learning models by reducing the amount of noise and redundancy in the data, as well as making the data more computationally efficient to process. Some of the modern methods of dimensionality reduction include:&lt;/p>
&lt;p>Principal Component Analysis (PCA): PCA is a popular technique used to reduce the dimensionality of a dataset by identifying the principal components that explain the most variance in the data. It works by projecting the data onto a new set of orthogonal axes, with each axis representing a principal component.&lt;/p>
&lt;p>t-Distributed Stochastic Neighbor Embedding (t-SNE): t-SNE is a nonlinear dimensionality reduction technique that is particularly effective for visualizing high-dimensional data. It works by mapping the high-dimensional data points to a low-dimensional space, while preserving the pairwise distances between the data points.&lt;/p>
&lt;p>Autoencoders: Autoencoders are neural networks that can be used for unsupervised learning and dimensionality reduction. They work by compressing the input data into a lower-dimensional representation, and then reconstructing the original input from this compressed representation.&lt;/p>
&lt;p>Non-negative Matrix Factorization (NMF): NMF is a matrix factorization technique that can be used for dimensionality reduction and feature extraction. It works by factorizing a non-negative matrix into two non-negative matrices, where the resulting factors can be interpreted as a lower-dimensional representation of the original data.&lt;/p>
&lt;p>UMAP (Uniform Manifold Approximation and Projection): UMAP is a newer technique for dimensionality reduction that is gaining popularity. It works by constructing a low-dimensional representation of the data that preserves both local and global structure, making it particularly useful for clustering and visualization tasks.&lt;/p>
&lt;p>These modern methods of dimensionality reduction offer a range of options to choose from, and selecting the most appropriate technique for a particular dataset depends on the nature of the data and the specific goals of the analysis.&lt;/p></description></item><item><title>Linear unmixing models on hyperspectral data</title><link>https://dkucharc.github.io/academic/projects/spectral_unmixing/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://dkucharc.github.io/academic/projects/spectral_unmixing/</guid><description>&lt;p>Linear unmixing is a popular technique used for analyzing hyperspectral data. Hyperspectral imaging is a remote sensing technique that captures the electromagnetic radiation reflected from the Earth&amp;rsquo;s surface across hundreds of narrow spectral bands. Linear unmixing is used to extract information about the different materials present in the scene based on their spectral signatures.&lt;/p>
&lt;p>The linear unmixing model assumes that each pixel in the hyperspectral image can be represented as a linear combination of the spectral signatures of the materials present in that pixel. In other words, the pixel&amp;rsquo;s spectrum is a weighted sum of the spectra of the constituent materials. This model is expressed mathematically as:&lt;/p>
&lt;p>𝐼(λ) = 𝑆(λ)𝐴&lt;/p>
&lt;p>where 𝐼(λ) is the observed spectrum at wavelength λ, 𝑆(λ) is the matrix of spectral signatures for the materials of interest, and 𝐴 is the abundance matrix that represents the proportion of each material present in the pixel.&lt;/p>
&lt;p>The linear unmixing process involves estimating the abundance matrix 𝐴 for each pixel in the image. This is typically done using optimization techniques such as least squares, non-negative least squares, or constrained least squares. Once the abundance matrix is estimated, the abundance maps can be generated for each material, providing information about the spatial distribution of the different materials in the scene.&lt;/p>
&lt;p>Linear unmixing is widely used in applications such as mineral mapping, vegetation analysis, and urban land-use classification, among others. It is a powerful tool for extracting information from hyperspectral data and can provide valuable insights into the Earth&amp;rsquo;s surface and its composition.&lt;/p></description></item><item><title>Optimization Methods for Financial Index Tracking</title><link>https://dkucharc.github.io/academic/projects/index_tracking/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://dkucharc.github.io/academic/projects/index_tracking/</guid><description>&lt;p>Financial index tracking is a popular investment strategy that involves investing in a portfolio of securities that mirrors the composition and performance of a particular financial index, such as the S&amp;amp;P 500 or the Dow Jones Industrial Average. The goal of index tracking is to achieve returns that closely match the performance of the chosen index, which is considered to be a benchmark for the overall market.&lt;/p>
&lt;p>Index tracking is typically achieved through passive investing, which involves buying and holding the constituent securities of the index in proportion to their weights in the index. This approach allows investors to benefit from the growth of the overall market without having to make individual stock selections.&lt;/p>
&lt;p>There are several advantages to index tracking. First, it offers broad exposure to a diversified portfolio of securities, which can reduce the risk of losses due to individual stock performance. Second, it typically has lower fees and expenses compared to actively managed funds, which can improve the overall returns for investors. Finally, it is a simple and transparent investment strategy that is easy to understand and implement.&lt;/p></description></item><item><title>Semantic Segmentation of Remote Sensing Images</title><link>https://dkucharc.github.io/academic/projects/unet_remote_sensing/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://dkucharc.github.io/academic/projects/unet_remote_sensing/</guid><description>&lt;p>Semantic segmentation in remote sensing refers to the process of segmenting an image obtained from a remote sensing platform (such as a satellite or drone) into different regions or objects based on their semantic meaning. This involves assigning each pixel in the image to a particular class or category, such as vegetation, water, buildings, roads, and so on.&lt;/p>
&lt;p>It has many applications, such as land cover classification, urban planning, environmental monitoring, and disaster management. It can be performed using a variety of techniques, including supervised and unsupervised machine learning algorithms, deep learning models, and image processing techniques.&lt;/p>
&lt;p>Some popular deep learning models used for semantic segmentation in remote sensing include U-Net, FCN, SegNet, and DeepLab. These models use convolutional neural networks (CNNs) to extract features from the input image and then apply a decoder to generate a pixel-wise segmentation map.&lt;/p></description></item><item><title>Time-series forecasting models based on DARTs</title><link>https://dkucharc.github.io/academic/projects/time_series_dart/</link><pubDate>Tue, 21 Mar 2023 00:00:00 +0000</pubDate><guid>https://dkucharc.github.io/academic/projects/time_series_dart/</guid><description/></item></channel></rss>