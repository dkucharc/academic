[{"authors":null,"categories":null,"content":"Daniel Kucharczyk is an Assistant Professor with the Faculty od Pure and Applied Mathematics at Wroclaw University of Technology. His research interests include the application of mathematics and AI/ML methods in finance, remote sensing and system recommendations.\n","date":1679356800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1679356800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Daniel Kucharczyk is an Assistant Professor with the Faculty od Pure and Applied Mathematics at Wroclaw University of Technology. His research interests include the application of mathematics and AI/ML methods in finance, remote sensing and system recommendations.","tags":null,"title":"Daniel Kucharczyk","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy‚Äôs Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://dkucharc.github.io/academic/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"Dimensionality reduction is a technique used in machine learning to reduce the number of features in a dataset. This can help to improve the performance of machine learning models by reducing the amount of noise and redundancy in the data, as well as making the data more computationally efficient to process. Some of the modern methods of dimensionality reduction include:\nPrincipal Component Analysis (PCA): PCA is a popular technique used to reduce the dimensionality of a dataset by identifying the principal components that explain the most variance in the data. It works by projecting the data onto a new set of orthogonal axes, with each axis representing a principal component.\nt-Distributed Stochastic Neighbor Embedding (t-SNE): t-SNE is a nonlinear dimensionality reduction technique that is particularly effective for visualizing high-dimensional data. It works by mapping the high-dimensional data points to a low-dimensional space, while preserving the pairwise distances between the data points.\nAutoencoders: Autoencoders are neural networks that can be used for unsupervised learning and dimensionality reduction. They work by compressing the input data into a lower-dimensional representation, and then reconstructing the original input from this compressed representation.\nNon-negative Matrix Factorization (NMF): NMF is a matrix factorization technique that can be used for dimensionality reduction and feature extraction. It works by factorizing a non-negative matrix into two non-negative matrices, where the resulting factors can be interpreted as a lower-dimensional representation of the original data.\nUMAP (Uniform Manifold Approximation and Projection): UMAP is a newer technique for dimensionality reduction that is gaining popularity. It works by constructing a low-dimensional representation of the data that preserves both local and global structure, making it particularly useful for clustering and visualization tasks.\nThese modern methods of dimensionality reduction offer a range of options to choose from, and selecting the most appropriate technique for a particular dataset depends on the nature of the data and the specific goals of the analysis.\n","date":1679356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679356800,"objectID":"f0ca8b7dedc59d1619cdde60cf990ab6","permalink":"https://dkucharc.github.io/academic/projects/dimensionality_reduction/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/dimensionality_reduction/","section":"projects","summary":"Dimensionality reduction is a technique used in machine learning to reduce the number of features in a dataset. This can help to improve the performance of machine learning models by reducing the amount of noise and redundancy in the data, as well as making the data more computationally efficient to process.","tags":["Bachelor","Free","ML","Remote Sensing"],"title":"Beyond classical dimensionality reduction techniques","type":"projects"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"Linear unmixing is a popular technique used for analyzing hyperspectral data. Hyperspectral imaging is a remote sensing technique that captures the electromagnetic radiation reflected from the Earth‚Äôs surface across hundreds of narrow spectral bands. Linear unmixing is used to extract information about the different materials present in the scene based on their spectral signatures.\nThe linear unmixing model assumes that each pixel in the hyperspectral image can be represented as a linear combination of the spectral signatures of the materials present in that pixel. In other words, the pixel‚Äôs spectrum is a weighted sum of the spectra of the constituent materials. This model is expressed mathematically as:\nùêº(Œª) = ùëÜ(Œª)ùê¥\nwhere ùêº(Œª) is the observed spectrum at wavelength Œª, ùëÜ(Œª) is the matrix of spectral signatures for the materials of interest, and ùê¥ is the abundance matrix that represents the proportion of each material present in the pixel.\nThe linear unmixing process involves estimating the abundance matrix ùê¥ for each pixel in the image. This is typically done using optimization techniques such as least squares, non-negative least squares, or constrained least squares. Once the abundance matrix is estimated, the abundance maps can be generated for each material, providing information about the spatial distribution of the different materials in the scene.\nLinear unmixing is widely used in applications such as mineral mapping, vegetation analysis, and urban land-use classification, among others. It is a powerful tool for extracting information from hyperspectral data and can provide valuable insights into the Earth‚Äôs surface and its composition.\n","date":1679356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679356800,"objectID":"34da234ef3e96633befe4b4de9cd2393","permalink":"https://dkucharc.github.io/academic/projects/spectral_unmixing/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/spectral_unmixing/","section":"projects","summary":"Linear unmixing is a popular technique used for analyzing hyperspectral data. Hyperspectral imaging is a remote sensing technique that captures the electromagnetic radiation reflected from the Earth‚Äôs surface across hundreds of narrow spectral bands.","tags":["Bachelor","Free","ML","Remote Sensing"],"title":"Linear unmixing models on hyperspectral data","type":"projects"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"Matrix factorization is a popular technique in machine learning used for dimensionality reduction, data compression, and collaborative filtering. It involves decomposing a matrix into two or more matrices that represent latent features or factors.\nThe goal of matrix factorization is to extract meaningful latent factors from a matrix that can be used to make predictions or recommendations. For example, in collaborative filtering, matrix factorization can be used to predict a user‚Äôs rating for an item based on their historical ratings and the ratings of similar users.\nMatrix factorization techniques are widely used in recommender systems to provide personalized recommendations to users based on their historical behavior or preferences. Here are some popular matrix factorization techniques used for recommender systems:\nSingular Value Decomposition (SVD): SVD is a widely used matrix factorization technique for recommender systems. It decomposes the user-item interaction matrix into two lower-rank matrices, which represent latent factors. These factors represent the user‚Äôs preferences and the item‚Äôs characteristics.\nAlternating Least Squares (ALS): ALS is another popular matrix factorization technique for recommender systems. It iteratively minimizes the error between the original matrix and the reconstructed matrix using alternating optimization techniques.\nNon-negative Matrix Factorization (NMF): NMF is a matrix factorization technique that factorizes the user-item interaction matrix into two non-negative matrices, which represent the user preferences and item characteristics. It is often used for recommender systems that require non-negative values.\nBayesian Personalized Ranking (BPR): BPR is a matrix factorization technique that learns latent factors for users and items by maximizing the likelihood of the observed interactions while minimizing the likelihood of unobserved interactions.\nFactorization Machines (FM): FM is a matrix factorization technique that can capture complex interactions between user preferences and item characteristics. It is a more powerful technique than SVD or NMF, but it requires more computational resources.\nThese techniques have different strengths and weaknesses and can be used depending on the specific needs of the recommender system.\n","date":1679356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679356800,"objectID":"1a5996d22e6b17de55d741b1a7922f9a","permalink":"https://dkucharc.github.io/academic/projects/20222023_factorization_machines/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/20222023_factorization_machines/","section":"projects","summary":"Matrix factorization is a popular technique in machine learning used for dimensionality reduction, data compression, and collaborative filtering. It involves decomposing a matrix into two or more matrices that represent latent features or factors.","tags":["Master","Booked"],"title":"Matrix factorization techniques for recommender systems","type":"projects"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"Financial index tracking is a popular investment strategy that involves investing in a portfolio of securities that mirrors the composition and performance of a particular financial index, such as the S\u0026amp;P 500 or the Dow Jones Industrial Average. The goal of index tracking is to achieve returns that closely match the performance of the chosen index, which is considered to be a benchmark for the overall market.\nIndex tracking is typically achieved through passive investing, which involves buying and holding the constituent securities of the index in proportion to their weights in the index. This approach allows investors to benefit from the growth of the overall market without having to make individual stock selections.\nThere are several advantages to index tracking. First, it offers broad exposure to a diversified portfolio of securities, which can reduce the risk of losses due to individual stock performance. Second, it typically has lower fees and expenses compared to actively managed funds, which can improve the overall returns for investors. Finally, it is a simple and transparent investment strategy that is easy to understand and implement.\n","date":1679356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679356800,"objectID":"c096cad9861507dafddf98bb94373f31","permalink":"https://dkucharc.github.io/academic/projects/index_tracking/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/index_tracking/","section":"projects","summary":"Financial index tracking is a popular investment strategy that involves investing in a portfolio of securities that mirrors the composition and performance of a particular financial index, such as the S\u0026P 500 or the Dow Jones Industrial Average.","tags":["Bachelor","Free","ML","Finance"],"title":"Optimization Methods for Financial Index Tracking","type":"projects"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"Semantic segmentation in remote sensing refers to the process of segmenting an image obtained from a remote sensing platform (such as a satellite or drone) into different regions or objects based on their semantic meaning. This involves assigning each pixel in the image to a particular class or category, such as vegetation, water, buildings, roads, and so on.\nIt has many applications, such as land cover classification, urban planning, environmental monitoring, and disaster management. It can be performed using a variety of techniques, including supervised and unsupervised machine learning algorithms, deep learning models, and image processing techniques.\nSome popular deep learning models used for semantic segmentation in remote sensing include U-Net, FCN, SegNet, and DeepLab. These models use convolutional neural networks (CNNs) to extract features from the input image and then apply a decoder to generate a pixel-wise segmentation map.\n","date":1679356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679356800,"objectID":"7440805f726efa666b6169b5c53fc217","permalink":"https://dkucharc.github.io/academic/projects/unet_remote_sensing/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/unet_remote_sensing/","section":"projects","summary":"Semantic segmentation in remote sensing refers to the process of segmenting an image obtained from a remote sensing platform (such as a satellite or drone) into different regions or objects based on their semantic meaning.","tags":["Bachelor","Free","ML","Remote Sensing"],"title":"Semantic Segmentation of Remote Sensing Images","type":"projects"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"","date":1679356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679356800,"objectID":"bd653819c2babb5585fda8ab8d1c7f04","permalink":"https://dkucharc.github.io/academic/projects/time_series_dart/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/time_series_dart/","section":"projects","summary":"","tags":["Bachelor","Free","ML","Time Series"],"title":"Time-series forecasting models based on DARTs","type":"projects"},{"authors":null,"categories":null,"content":"Basic information\nForm of the classes: tutorials Lecturer: prof. Zbigniew Palmowski, DSc, PhD Audience: Students of Applied Mathematics, Faculty of Pure and Applied Mathematics (W-13), 1st semestr Time and place of the classes\nFridays, 9:15 AM - 11:00 AM (Building C-19, Room: A.1.3) Fridays, 11:15 AM - 1:00 PM (Building C-19, Room: A.1.3) Grading rules\nDuring the term there will be one test and one exam. The test will take place during the tutorials, around the 9th week of the classes. The maximum number of points to be scored at the test is 70 points. The exam will take place at the end of the term, during the exam session. The maximum number of points to be scored at the exam is also 70 points. Evert student have an obligation to solve at least one problem from the official problem lists. This form of scoring points is called in-class activity. For each completely solved problem, a student can score 10 points. The problem is considered to be fully solved when the following requirements are met: the solution is correct, the solution is presented during the classes, the presented solution has to be delivered in the LaTeX format to the tutor‚Äôs email. The provided LaTeX file is meant to be based on the following template. A student cannot score more than a total of 70 points from the test and from in-class activity. Scoring 70 points that way frees the student from the obligation of taking a written part of the exam and guarantees him/her the final 5.0 grade in advance. Students being graded below 70 points (from the test and from in-class activity) have an obligation to take an exam. The final grade from the class is given in reference to the sum of the scores achieved from test, the in-class activity and the exam and it can derived from the table given below. Points Grade \u0026lt; 65 2.0 [65;80) 3.0 [80;90) 3.5 [90;105) 4.0 [105;120) 4.5 \u0026lt;= 120 5.0 Note: There is a possibility of getting an excellent (5.5) grade. People aiming to get it will be asked to take an extra (oral) part of the exam. A willingness to take the exam should be accepted by the Tutor and reported to the Lecturer, accordingly. Timelines:\nWeek 1 (2023-03-03) - Skipped class due to Dean‚Äôs hours. Week 2 (2023-03-10) - Binomial option pricing models. Problem Sheet#1 Solved problems: 1, 2, 3 Week 3 (2023-03-17) - Introduction to the stochastic differential equations (SDEs) and stochastic integrals. s. Problem Sheet#2 Week 4 (2023-03-24) - Problem Sheet#2 Week 5 (2023-03-31) - Problem Sheet#2 Week 6 (2023-04-14) - Problem Sheet#2 Week 7 (2023-04-21) - Problem Sheet#3 Week 8 (2023-04-28) - Problem Sheet#3 Mid Term Test (2023-05-10) - Mid Term Test Week 9 (2023-05-12) - Problem Sheet#3 Note: Below you will find a link to the folder containing unreviewed(!) solutions: link\n","date":1677801600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1677801600,"objectID":"fa60274ea1f83ff53f2eea8115e44175","permalink":"https://dkucharc.github.io/academic/teaching/2022_2023/summer/economathematics/","publishdate":"2023-03-03T00:00:00Z","relpermalink":"/academic/teaching/2022_2023/summer/economathematics/","section":"teaching","summary":"Complementary class to Economathematics course given by [Prof. Zbigniew Palmowski, DSc, PhD](http://prac.im.pwr.wroc.pl/~zpalma/econ.html) at WUST during summer term, 2022/2023.","tags":["Summer (2022/2023)"],"title":"Economathematics","type":"teaching"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"Black-box machine learning models are now routinely used in high-risk settings, like medical diagnostics, which demand uncertainty quantification to avoid consequential model failures. Conformal prediction is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions. One can use conformal prediction with any pre-trained model, such as a neural network, to produce sets that are guaranteed to contain the ground truth with a user-specified probability, such as 90%. It is easy-to-understand, easy-to-use, and general, applying naturally to problems arising in the fields of computer vision, natural language processing, deep reinforcement learning, and so on.\n","date":1670198400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670198400,"objectID":"9796519abf02cd90709c7027619682cb","permalink":"https://dkucharc.github.io/academic/projects/conformal_prediction/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/conformal_prediction/","section":"projects","summary":"Black-box machine learning models are now routinely used in high-risk settings, like medical diagnostics, which demand uncertainty quantification to avoid consequential model failures. Conformal prediction is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models.","tags":["Master"],"title":"Conformal Prediction and Distribution-Free Uncertainty Quantification","type":"projects"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"Data drift is a common problem in machine learning where the statistical properties of the data used for model training change over time. This can lead to a drop in model performance, as the model is no longer optimized for the new distribution of data.\nData drift can occur for many reasons, such as changes in the data collection process, changes in user behavior, or changes in the underlying system being modeled. To mitigate data drift, it is important to monitor the performance of the model over time and retrain it with updated data when necessary.\nThere are several techniques that can be used to detect and address data drift, including:\nMonitoring key performance metrics such as accuracy, precision, and recall over time to detect drops in model performance.\nUsing statistical tests to compare the distributions of the data used for training and testing the model.\nUsing data augmentation techniques such as synthetic data generation to supplement the training data and make the model more robust to changes in the data distribution.\nEmploying domain adaptation techniques to adapt the model to new data distributions, while minimizing the need for retraining the entire model.\nBy proactively monitoring and addressing data drift, machine learning models can maintain high levels of accuracy and continue to provide valuable insights even as data distribution changes over time.\n","date":1670198400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670198400,"objectID":"e4c2d8f95f2c6354e2af1bf93aabfcbe","permalink":"https://dkucharc.github.io/academic/projects/data_drift/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/data_drift/","section":"projects","summary":"Data drift is a common problem in machine learning where the statistical properties of the data used for model training change over time. This can lead to a drop in model performance, as the model is no longer optimized for the new distribution of data.","tags":[],"title":"Mathematical aspects of data drift in machine learning","type":"projects"},{"authors":["Daniel Kucharczyk","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It‚Äôs a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy‚Äôs future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://dkucharc.github.io/academic/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/academic/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://dkucharc.github.io/academic/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/academic/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Daniel Kucharczyk","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"ff6a19061a984819d30c916886db56ef","permalink":"https://dkucharc.github.io/academic/publication/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/publication/example/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"An example conference paper","type":"publication"}]