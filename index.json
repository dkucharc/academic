[{"authors":null,"categories":null,"content":"Daniel Kucharczyk is an Assistant Professor with the Faculty od Pure and Applied Mathematics at Wroclaw University of Technology. His research interests include the application of mathematics and AI/ML methods in finance, remote sensing and system recommendations.\n","date":1679356800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1679356800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Daniel Kucharczyk is an Assistant Professor with the Faculty od Pure and Applied Mathematics at Wroclaw University of Technology. His research interests include the application of mathematics and AI/ML methods in finance, remote sensing and system recommendations.","tags":null,"title":"Daniel Kucharczyk","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy‚Äôs Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://dkucharc.github.io/academic/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"Dimensionality reduction is a technique used in machine learning to reduce the number of features in a dataset. This can help to improve the performance of machine learning models by reducing the amount of noise and redundancy in the data, as well as making the data more computationally efficient to process. Some of the modern methods of dimensionality reduction include:\nPrincipal Component Analysis (PCA): PCA is a popular technique used to reduce the dimensionality of a dataset by identifying the principal components that explain the most variance in the data. It works by projecting the data onto a new set of orthogonal axes, with each axis representing a principal component.\nt-Distributed Stochastic Neighbor Embedding (t-SNE): t-SNE is a nonlinear dimensionality reduction technique that is particularly effective for visualizing high-dimensional data. It works by mapping the high-dimensional data points to a low-dimensional space, while preserving the pairwise distances between the data points.\nAutoencoders: Autoencoders are neural networks that can be used for unsupervised learning and dimensionality reduction. They work by compressing the input data into a lower-dimensional representation, and then reconstructing the original input from this compressed representation.\nNon-negative Matrix Factorization (NMF): NMF is a matrix factorization technique that can be used for dimensionality reduction and feature extraction. It works by factorizing a non-negative matrix into two non-negative matrices, where the resulting factors can be interpreted as a lower-dimensional representation of the original data.\nUMAP (Uniform Manifold Approximation and Projection): UMAP is a newer technique for dimensionality reduction that is gaining popularity. It works by constructing a low-dimensional representation of the data that preserves both local and global structure, making it particularly useful for clustering and visualization tasks.\nThese modern methods of dimensionality reduction offer a range of options to choose from, and selecting the most appropriate technique for a particular dataset depends on the nature of the data and the specific goals of the analysis.\n","date":1679356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679356800,"objectID":"f0ca8b7dedc59d1619cdde60cf990ab6","permalink":"https://dkucharc.github.io/academic/projects/dimensionality_reduction/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/dimensionality_reduction/","section":"projects","summary":"Dimensionality reduction is a technique used in machine learning to reduce the number of features in a dataset. This can help to improve the performance of machine learning models by reducing the amount of noise and redundancy in the data, as well as making the data more computationally efficient to process.","tags":["Bachelor","Free","ML","Remote Sensing"],"title":"Beyond classical dimensionality reduction techniques","type":"projects"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"Linear unmixing is a popular technique used for analyzing hyperspectral data. Hyperspectral imaging is a remote sensing technique that captures the electromagnetic radiation reflected from the Earth‚Äôs surface across hundreds of narrow spectral bands. Linear unmixing is used to extract information about the different materials present in the scene based on their spectral signatures.\nThe linear unmixing model assumes that each pixel in the hyperspectral image can be represented as a linear combination of the spectral signatures of the materials present in that pixel. In other words, the pixel‚Äôs spectrum is a weighted sum of the spectra of the constituent materials. This model is expressed mathematically as:\nùêº(Œª) = ùëÜ(Œª)ùê¥\nwhere ùêº(Œª) is the observed spectrum at wavelength Œª, ùëÜ(Œª) is the matrix of spectral signatures for the materials of interest, and ùê¥ is the abundance matrix that represents the proportion of each material present in the pixel.\nThe linear unmixing process involves estimating the abundance matrix ùê¥ for each pixel in the image. This is typically done using optimization techniques such as least squares, non-negative least squares, or constrained least squares. Once the abundance matrix is estimated, the abundance maps can be generated for each material, providing information about the spatial distribution of the different materials in the scene.\nLinear unmixing is widely used in applications such as mineral mapping, vegetation analysis, and urban land-use classification, among others. It is a powerful tool for extracting information from hyperspectral data and can provide valuable insights into the Earth‚Äôs surface and its composition.\n","date":1679356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679356800,"objectID":"34da234ef3e96633befe4b4de9cd2393","permalink":"https://dkucharc.github.io/academic/projects/spectral_unmixing/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/spectral_unmixing/","section":"projects","summary":"Linear unmixing is a popular technique used for analyzing hyperspectral data. Hyperspectral imaging is a remote sensing technique that captures the electromagnetic radiation reflected from the Earth‚Äôs surface across hundreds of narrow spectral bands.","tags":["Bachelor","Free","ML","Remote Sensing"],"title":"Linear unmixing models on hyperspectral data","type":"projects"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"Financial index tracking is a popular investment strategy that involves investing in a portfolio of securities that mirrors the composition and performance of a particular financial index, such as the S\u0026amp;P 500 or the Dow Jones Industrial Average. The goal of index tracking is to achieve returns that closely match the performance of the chosen index, which is considered to be a benchmark for the overall market.\nIndex tracking is typically achieved through passive investing, which involves buying and holding the constituent securities of the index in proportion to their weights in the index. This approach allows investors to benefit from the growth of the overall market without having to make individual stock selections.\nThere are several advantages to index tracking. First, it offers broad exposure to a diversified portfolio of securities, which can reduce the risk of losses due to individual stock performance. Second, it typically has lower fees and expenses compared to actively managed funds, which can improve the overall returns for investors. Finally, it is a simple and transparent investment strategy that is easy to understand and implement.\n","date":1679356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679356800,"objectID":"c096cad9861507dafddf98bb94373f31","permalink":"https://dkucharc.github.io/academic/projects/index_tracking/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/index_tracking/","section":"projects","summary":"Financial index tracking is a popular investment strategy that involves investing in a portfolio of securities that mirrors the composition and performance of a particular financial index, such as the S\u0026P 500 or the Dow Jones Industrial Average.","tags":["Bachelor","Free","ML","Finance"],"title":"Optimization Methods for Financial Index Tracking","type":"projects"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"Semantic segmentation in remote sensing refers to the process of segmenting an image obtained from a remote sensing platform (such as a satellite or drone) into different regions or objects based on their semantic meaning. This involves assigning each pixel in the image to a particular class or category, such as vegetation, water, buildings, roads, and so on.\nIt has many applications, such as land cover classification, urban planning, environmental monitoring, and disaster management. It can be performed using a variety of techniques, including supervised and unsupervised machine learning algorithms, deep learning models, and image processing techniques.\nSome popular deep learning models used for semantic segmentation in remote sensing include U-Net, FCN, SegNet, and DeepLab. These models use convolutional neural networks (CNNs) to extract features from the input image and then apply a decoder to generate a pixel-wise segmentation map.\n","date":1679356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679356800,"objectID":"7440805f726efa666b6169b5c53fc217","permalink":"https://dkucharc.github.io/academic/projects/unet_remote_sensing/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/unet_remote_sensing/","section":"projects","summary":"Semantic segmentation in remote sensing refers to the process of segmenting an image obtained from a remote sensing platform (such as a satellite or drone) into different regions or objects based on their semantic meaning.","tags":["Bachelor","Free","ML","Remote Sensing"],"title":"Semantic Segmentation of Remote Sensing Images","type":"projects"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"","date":1679356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679356800,"objectID":"bd653819c2babb5585fda8ab8d1c7f04","permalink":"https://dkucharc.github.io/academic/projects/time_series_dart/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/time_series_dart/","section":"projects","summary":"","tags":["Bachelor","Free","ML","Time Series"],"title":"Time-series forecasting models based on DARTs","type":"projects"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"Black-box machine learning models are now routinely used in high-risk settings, like medical diagnostics, which demand uncertainty quantification to avoid consequential model failures. Conformal prediction is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions. One can use conformal prediction with any pre-trained model, such as a neural network, to produce sets that are guaranteed to contain the ground truth with a user-specified probability, such as 90%. It is easy-to-understand, easy-to-use, and general, applying naturally to problems arising in the fields of computer vision, natural language processing, deep reinforcement learning, and so on.\n","date":1670198400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670198400,"objectID":"9796519abf02cd90709c7027619682cb","permalink":"https://dkucharc.github.io/academic/projects/conformal_prediction/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/conformal_prediction/","section":"projects","summary":"Black-box machine learning models are now routinely used in high-risk settings, like medical diagnostics, which demand uncertainty quantification to avoid consequential model failures. Conformal prediction is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models.","tags":["Master"],"title":"Conformal Prediction and Distribution-Free Uncertainty Quantification","type":"projects"},{"authors":["Daniel Kucharczyk"],"categories":null,"content":"Data drift is a common problem in machine learning where the statistical properties of the data used for model training change over time. This can lead to a drop in model performance, as the model is no longer optimized for the new distribution of data.\nData drift can occur for many reasons, such as changes in the data collection process, changes in user behavior, or changes in the underlying system being modeled. To mitigate data drift, it is important to monitor the performance of the model over time and retrain it with updated data when necessary.\nThere are several techniques that can be used to detect and address data drift, including:\nMonitoring key performance metrics such as accuracy, precision, and recall over time to detect drops in model performance.\nUsing statistical tests to compare the distributions of the data used for training and testing the model.\nUsing data augmentation techniques such as synthetic data generation to supplement the training data and make the model more robust to changes in the data distribution.\nEmploying domain adaptation techniques to adapt the model to new data distributions, while minimizing the need for retraining the entire model.\nBy proactively monitoring and addressing data drift, machine learning models can maintain high levels of accuracy and continue to provide valuable insights even as data distribution changes over time.\n","date":1670198400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670198400,"objectID":"e4c2d8f95f2c6354e2af1bf93aabfcbe","permalink":"https://dkucharc.github.io/academic/projects/data_drift/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/projects/data_drift/","section":"projects","summary":"Data drift is a common problem in machine learning where the statistical properties of the data used for model training change over time. This can lead to a drop in model performance, as the model is no longer optimized for the new distribution of data.","tags":[],"title":"Mathematical aspects of data drift in machine learning","type":"projects"},{"authors":null,"categories":null,"content":"Course Summary This course provides a broad introduction to machine learning and statistical pattern recognition with the main focus on the deep learning methods.\nTime and Location\nWinter Term, 2023/2024\nThursday 1:15 PM - 3:00 PM, C13, A.1.13\nGrading \u0026amp; Rules\nThe course is divided into two streams. Namely, in-class lectures and labs. In total, a student can obtain up to 50 points. The maximum number of points that can be achieved for labs is 34 points. A student can get additional 16 points from the oral exam that will take place during the examination session. To obtain a positive mark it is sufficient and necessary to obtain at least 25 points total. Then, the final grade is calculated as follows: POINTS GRADE [25, 30) 3.0 [30, 35) 3.5 [35, 40) 4.0 [40, 45) 4.5 [45, 50] 5.0 Syllabus\nEVENT DATE LECTURE ADDITIONAL MATERIALS Lecture 1 05/10/2023 Topics:\n- Class introduction - Course details Lecture 2 12/10/2023 Topics:\n- Machine Learning introduction Lecture 3 19/10/2023 Topics:\n- Supervised Learning Suggested readings: - Notes On Supervised Learning Lecture 4 26/10/2023 Lecture cancelled. To be retaken soon. Lecture 5 09/11/2023 Topics:\n- Generalization Error - Bias-Variance Decomposition Suggested readings: - Andrew Ng‚Äôs Lecutre Notes On Learning Theory\n- Notes on Bias-Variance Trade Off Lecture 6 16/11/2023 Topics:\n- Overfitting. Regularization Suggested readings: - Sebastian Rascha‚Äôs Lecture Notes On Regularization\n- Rogger‚Äôs Grosse Notes Lecture 7 23/11/2023 Topics:\n- Introduction to Neural Networks\n- Backpropagation Suggested readings: - Neurals network from scratch\n- Brief introduction to backpropagation Lecture 8 30/11/2023 TBA Lecture 9 07/12/2023 TBA Lecture 10 14/12/2023 TBA Lecture 11 21/12/2023 TBA Lecture 12 11/01/2024 TBA Lecture 13 18/01/2024 TBA Lecture 14 25/01/2024 TBA Lecture 15 01/02/2024 TBA Materials\nHastie, T., Tibshirani, R.,, Friedman, J. (2001). The Elements of Statistical Learning. New York, NY, USA: Springer New York Inc.. PDF Version Goodfellow, I., Bengio, Y., \u0026amp; Courville, A. (2016). Deep learning. MIT Press. Online Version ","date":1665273600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665273600,"objectID":"a6ba4ed1cd6aaa48c657c7ad5e3a7b78","permalink":"https://dkucharc.github.io/academic/teaching/2023_2024/winter/machine_learning/","publishdate":"2022-10-09T00:00:00Z","relpermalink":"/academic/teaching/2023_2024/winter/machine_learning/","section":"teaching","summary":"The course is hosted as a part of the Winter Term 2023/2024 for students from Applied Mathematics specialization at the Faculty of Pure and Applied Mathematics, Wroclaw University of Science and Technology.","tags":["Winter (2023/2024)"],"title":"Machine Learning","type":"teaching"},{"authors":["Daniel Kucharczyk","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It‚Äôs a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more Get Started üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy‚Äôs future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you‚Äôll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://dkucharc.github.io/academic/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/academic/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://dkucharc.github.io/academic/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/academic/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Daniel Kucharczyk","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"ff6a19061a984819d30c916886db56ef","permalink":"https://dkucharc.github.io/academic/publication/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/academic/publication/example/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"An example conference paper","type":"publication"}]